{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Class_label  Feature_1  Feature_2  Feature_3\n",
      "0            0        NaN        NaN   -0.36098\n",
      "1            1        NaN        NaN        NaN\n",
      "2            1   6.422475   6.496080        NaN\n",
      "3            0        NaN        NaN        NaN\n",
      "4            1        NaN   5.673988    4.38316\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "complete = pd.read_csv('../data/artificial_data_3features.csv')\n",
    "\n",
    "print(complete.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: train, test, holdout speration\n",
    "\n",
    "def dataset_speration(complete):\n",
    "    complete = complete.sample(frac=1).reset_index(drop=True) # shuffle\n",
    "    total_row = complete.shape[0]\n",
    "    train = complete.loc[0:int(total_row * 0.6)-1].reset_index(drop=True)\n",
    "    test = complete.loc[int(total_row *0.6):int(total_row *0.8)-1].reset_index(drop=True)\n",
    "    holdout = complete.loc[int(total_row *0.8):total_row].reset_index(drop=True)\n",
    "    \n",
    "    return train, test, holdout\n",
    "\n",
    "# Function: Gerneral XGB model\n",
    "\n",
    "def xgb_model(X_train, Y_train, X_test, Y_test, X_holdout, Y_holdout):\n",
    "\n",
    "    XGB = xgb.XGBClassifier()\n",
    "    # find the best parameter set\n",
    "    param_grid = {\"learning_rate\": [0.1],\n",
    "                  \"objective\":['binary:logistic'],\n",
    "                  \"reg_alpha\": [0.1,1.],\n",
    "                  \"missing\": [np.nan], \n",
    "                  \"reg_lambda\": [0.1,1.]}\n",
    "\n",
    "    scores = np.zeros(len(ParameterGrid(param_grid)))\n",
    "\n",
    "    for i in range(len(ParameterGrid(param_grid))):\n",
    "        params = ParameterGrid(param_grid)[i]\n",
    "        XGB.set_params(**params)\n",
    "        eval_set = [(X_test, Y_test)]\n",
    "        XGB.fit(X_train, Y_train, \n",
    "                early_stopping_rounds=50, \n",
    "                eval_metric=\"error\", eval_set=eval_set,verbose=False)# with early stopping\n",
    "        Y_test_pred = XGB.predict(X_test, ntree_limit=XGB.best_ntree_limit)\n",
    "        scores[i] = accuracy_score(Y_test,Y_test_pred)\n",
    "\n",
    "    best_params = np.array(ParameterGrid(param_grid))[scores == np.max(scores)]\n",
    "    #print ('Test set max score and best parameters are:')\n",
    "    #print (np.max(scores))\n",
    "    #print (best_params)\n",
    "\n",
    "    # test the model on the holdout set with best parameter set\n",
    "    XGB.set_params(**best_params[0])\n",
    "    XGB.fit(X_train,Y_train, \n",
    "            early_stopping_rounds=50, \n",
    "            eval_metric=\"error\", eval_set=eval_set,verbose=False)\n",
    "    Y_holdout_pred = XGB.predict(X_holdout, ntree_limit=XGB.best_ntree_limit)\n",
    "    cnf_matrix = confusion_matrix(Y_holdout,Y_holdout_pred)\n",
    "\n",
    "    print ('The accuracy is:',accuracy_score(Y_holdout,Y_holdout_pred))\n",
    "    print ('The confusion matrix is:')\n",
    "    print (cnf_matrix)\n",
    "    \n",
    "    return Y_holdout_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Reduced-feature XGB model\n",
    "# all the inputs need to be pandas DataFrame\n",
    "\n",
    "def reduced_feature_xgb(X_train, Y_train, X_test, Y_test, X_holdout, Y_holdout):\n",
    "    \n",
    "    # find all unique patterns of missing value in holdout set\n",
    "    mask = X_holdout.isnull()\n",
    "    unique_rows = np.array(np.unique(mask, axis=0))\n",
    "    all_Y_holdout_pred = pd.DataFrame()\n",
    "    \n",
    "    print('there are', len(unique_rows), 'unique missing value patterns.')\n",
    "    print(unique_rows)\n",
    "    \n",
    "    # divide holdout sets into subgroups according to the unique patterns\n",
    "    for i in range(len(unique_rows)):\n",
    "        print ('working on unique pattern', i)\n",
    "        ## generate X_holdout subset that matches the unique pattern i\n",
    "        sub_X_holdout = pd.DataFrame()\n",
    "        sub_Y_holdout = pd.DataFrame()\n",
    "        for j in range(len(mask)): # check each row in mask\n",
    "            row_mask = np.array(mask.iloc[j])\n",
    "            if np.array_equal(row_mask, unique_rows[i]): # if the pattern matches the ith unique pattern\n",
    "                sub_X_holdout = sub_X_holdout.append(X_holdout.iloc[j])# append the according X_holdout row j to the subset\n",
    "                sub_Y_holdout = sub_Y_holdout.append(Y_holdout.iloc[j]).astype(int) # append the according Y_holdout row j\n",
    "        sub_X_holdout = sub_X_holdout[sub_X_holdout.columns[~unique_rows[i]]]\n",
    "        \n",
    "        ## choose the according reduced features for subgroups\n",
    "        sub_X_train = pd.DataFrame()\n",
    "        sub_Y_train = pd.DataFrame()\n",
    "        sub_X_test = pd.DataFrame()\n",
    "        sub_Y_test = pd.DataFrame()\n",
    "        # 1.cut the feature columns that have nans in the according sub_X_holdout\n",
    "        sub_X_train = X_train[X_train.columns[~unique_rows[i]]]\n",
    "        sub_X_test = X_test[X_test.columns[~unique_rows[i]]]\n",
    "        # 2.cut the rows in the sub_X_train and sub_X_test that have any nans\n",
    "        sub_X_train = sub_X_train.dropna()\n",
    "        sub_X_test = sub_X_test.dropna()   \n",
    "        # 3.cut the sub_Y_train and sub_Y_test accordingly\n",
    "        sub_Y_train = Y_train.iloc[sub_X_train.index]\n",
    "        sub_Y_test = Y_test.iloc[sub_X_test.index]\n",
    "        \n",
    "        #print(sub_X_train)\n",
    "        #print(sub_Y_train)\n",
    "        #print(sub_X_test)\n",
    "        #print(sub_Y_test)\n",
    "        #print(sub_X_holdout)\n",
    "        #print(sub_Y_holdout)\n",
    "        \n",
    "        ## check if sub_X_train or sub_X_test is empty:\n",
    "        if (sub_X_train.size == 0 or \n",
    "            sub_X_test.size == 0 or \n",
    "            len(np.unique(sub_Y_train)) == 1):\n",
    "            \n",
    "            if (Y_train['Class_label'] == 0).sum() >= (Y_train['Class_label'] == 1).sum():\n",
    "                sub_Y_holdout_pred = pd.DataFrame(0, index=np.arange(len(sub_Y_holdout)), columns=['sub_Y_holdout_pred'])\n",
    "            else:\n",
    "                sub_Y_holdout_pred = pd.DataFrame(1, index=np.arange(len(sub_Y_holdout)), columns=['sub_Y_holdout_pred'])\n",
    "                        \n",
    "        else:\n",
    "            \n",
    "            ## call xgb function for the subgroups: train and test by local reduced features\n",
    "            sub_Y_train_list = sub_Y_train[sub_Y_train.columns[0]].tolist()\n",
    "            sub_Y_test_list = sub_Y_test[sub_Y_test.columns[0]].tolist()\n",
    "            sub_Y_holdout_list = sub_Y_holdout[sub_Y_holdout.columns[0]].tolist()\n",
    "        \n",
    "            sub_Y_holdout_pred = xgb_model(sub_X_train, sub_Y_train_list, sub_X_test, \n",
    "                                           sub_Y_test_list, sub_X_holdout, sub_Y_holdout_list)\n",
    "            sub_Y_holdout_pred = pd.DataFrame(sub_Y_holdout_pred,columns=['sub_Y_holdout_pred'],\n",
    "                                              index=sub_Y_holdout.index)\n",
    "            \n",
    "        all_Y_holdout_pred = all_Y_holdout_pred.append(sub_Y_holdout_pred)\n",
    "        \n",
    "    # rank the final Y_holdout_pred according to original Y_holdout index\n",
    "    all_Y_holdout_pred = all_Y_holdout_pred.sort_index()\n",
    "    print(all_Y_holdout_pred)\n",
    "               \n",
    "    # get global accuracy and the confusion matrix\n",
    "    total_accuracy_score= accuracy_score(Y_holdout,all_Y_holdout_pred)\n",
    "    total_cnf_matrix = confusion_matrix(Y_holdout,all_Y_holdout_pred)\n",
    "    \n",
    "    return total_accuracy_score, total_cnf_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 7 unique missing value patterns.\n",
      "[[False False  True]\n",
      " [False  True False]\n",
      " [False  True  True]\n",
      " [ True False False]\n",
      " [ True False  True]\n",
      " [ True  True False]\n",
      " [ True  True  True]]\n",
      "working on unique pattern 0\n",
      "The accuracy is: 1.0\n",
      "The confusion matrix is:\n",
      "[[1]]\n",
      "working on unique pattern 1\n",
      "The accuracy is: 1.0\n",
      "The confusion matrix is:\n",
      "[[2]]\n",
      "working on unique pattern 2\n",
      "The accuracy is: 1.0\n",
      "The confusion matrix is:\n",
      "[[1]]\n",
      "working on unique pattern 3\n",
      "The accuracy is: 1.0\n",
      "The confusion matrix is:\n",
      "[[2]]\n",
      "working on unique pattern 4\n",
      "The accuracy is: 1.0\n",
      "The confusion matrix is:\n",
      "[[2 0]\n",
      " [0 1]]\n",
      "working on unique pattern 5\n",
      "The accuracy is: 1.0\n",
      "The confusion matrix is:\n",
      "[[3 0]\n",
      " [0 1]]\n",
      "working on unique pattern 6\n",
      "    sub_Y_holdout_pred\n",
      "0                    0\n",
      "1                    0\n",
      "1                    0\n",
      "2                    0\n",
      "2                    0\n",
      "3                    1\n",
      "3                    0\n",
      "4                    0\n",
      "5                    0\n",
      "5                    1\n",
      "6                    0\n",
      "6                    0\n",
      "7                    1\n",
      "8                    1\n",
      "9                    0\n",
      "11                   1\n",
      "13                   1\n",
      "14                   0\n",
      "16                   0\n",
      "19                   1\n",
      "the total accuracy of the reduced feature model is: 0.45\n",
      "the total confusion matrix is:\n",
      "[[6 4]\n",
      " [7 3]]\n"
     ]
    }
   ],
   "source": [
    "# reduced model test\n",
    "\n",
    "train, test, holdout = dataset_speration(complete)\n",
    "#print(train)\n",
    "#print(test)\n",
    "#print(holdout)\n",
    "\n",
    "X_train = train.iloc[:,1:]\n",
    "Y_train = pd.DataFrame(train['Class_label'])\n",
    "X_test = test.iloc[:,1:]\n",
    "Y_test = pd.DataFrame(test['Class_label'])\n",
    "X_holdout = holdout.iloc[:,1:]\n",
    "Y_holdout = pd.DataFrame(holdout['Class_label'])\n",
    "\n",
    "#print(X_train)\n",
    "#print(Y_train)\n",
    "#print(X_test)\n",
    "#print(Y_test)\n",
    "#print(X_holdout)\n",
    "#print(Y_holdout)\n",
    "\n",
    "total_accuracy_score, total_cnf_matrix = reduced_feature_xgb(X_train, Y_train, X_test, Y_test, X_holdout, Y_holdout)\n",
    "print('the total accuracy of the reduced feature model is:', total_accuracy_score)\n",
    "print('the total confusion matrix is:')\n",
    "print(total_cnf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,1,1])\n",
    "print (np.unique(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
